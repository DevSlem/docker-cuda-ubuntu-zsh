services:
  <USER_NAME>.ai-dev-env-base: # <USER_NAME> as your user name
    build:
      context: ./<DIR_NAME> # Dockerfile path
    image: ai-dev-env:<VERSION>-<DIR_NAME>
    container_name: <USER_NAME>.ai-dev-env-base # <USER_NAME> as your user name
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    ports:
      - "<HOST_PORT>:22" # <HOST_PORT> as your host port for SSH port forwarding (host:container) 
    volumes:
      - /home/<USER_NAME>/workspace:/root/workspace # <USER_NAME> as your host user name for binding host workspace to container workspace for persistency
      # - external-disk1:/mnt/data1 # bind external disk to container
    environment:
      - NVIDIA_VISIBLE_DEVICES=all # visible all GPUs
      - SSH_PUBLIC_KEY=${SSH_PUBLIC_KEY} # SSH public key
    stdin_open: true
    tty: true
    ipc: host # It is useful when you use multiple workers in PyTorch.

# If you want to bind external disk to container, you can use the following code
# volumes:
#   # Define the docker volume
#   external-disk1:
#     external: true
